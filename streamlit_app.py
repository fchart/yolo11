#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
-------------------------------------------------
   @File Name:     app.py
   @Author:        Luyao.zhang
   @Date:          2023/5/15
   @Update Date:   2024/11/22 ä¿®æ”¹å’Œä¸­æ–‡åŒ– By é™³æœƒå®‰
   @Description:
-------------------------------------------------
"""
from pathlib import Path
from PIL import Image
import streamlit as st
import sys
from ultralytics import YOLO
import cv2
from PIL import Image
import tempfile

# å–å¾—ç›®å‰æª”æ¡ˆçš„çµ•å°è·¯å¾‘
file_path = Path(__file__).resolve()

# å–å¾—ç›®å‰æª”æ¡ˆçš„çˆ¶è·¯å¾‘
root_path = file_path.parent

# å¦‚æœæ ¹è·¯å¾‘ä¸å­˜åœ¨ sys.path ä¸²åˆ—, åœ¨ sys.pathè·¯å¾‘åŠ ä¸Šæ ¹è·¯å¾‘
if root_path not in sys.path:
    sys.path.append(str(root_path))

# å–å¾—æ ¹ç›®éŒ„å’Œç›®å‰å·¥ä½œç›®éŒ„çš„ç›¸å°ç›®éŒ„
ROOT = root_path.relative_to(Path.cwd())

# è³‡æ–™ä¾†æº
SOURCES_LIST = ["åœ–ç‰‡", "å½±ç‰‡", "ç¶²è·¯æ”å½±æ©ŸWebcam", "ç¶²è·¯ç›£æ§æ”å½±æ©ŸIPcam"]

# YOLO ç‰©é«”åµæ¸¬æ¨¡å‹è¨­ç½®
DETECTION_MODEL_DIR = ROOT / 'weights' / 'detection'
# YOLO å§¿æ…‹è©•ä¼°æ¨¡å‹è¨­ç½®
POSE_MODEL_DIR = ROOT / 'weights' / 'pos'

DETECTION_MODEL_LIST = [
    "yolo11n.pt",
    "yolo11s.pt",
    "yolo11m.pt",
    "yolo11l.pt",
    "yolo11x.pt",
    "best.pt"]

POSE_MODEL_LIST = [
    "yolo11n-pose.pt",
    "yolo11s-pose.pt",
    "yolo11m-pose.pt",
    "yolo11l-pose.pt",
    "yolo11x-pose.pt",
    "best.pt"]

def _display_detected_frames(conf, model, st_frame, image, task_type):
    """
    ä½¿ç”¨ YOLO11 æ¨¡å‹åœ¨å½±ç‰‡å¹€ä¸Šæ¨™è¨˜å‡ºåµæ¸¬åˆ°çš„ç‰©é«”ã€‚
    :param conf (float): ç‰©é«”åµæ¸¬çš„ä¿¡å¿ƒæŒ‡æ•¸é–¾å€¼ã€‚
    :param model (YOLO11): YOLO11 æ¨¡å‹çš„å¯¦ä¾‹ã€‚
    :param st_frame (Streamlit ç‰©ä»¶): ç”¨æ–¼é¡¯ç¤ºåµæ¸¬å½±ç‰‡çµæœçš„ Streamlit ç‰©ä»¶ã€‚
    :param image (numpy é™£åˆ—): å½±ç‰‡å¹€çš„ numpy é™£åˆ—ã€‚
    :param task_type (string): YOLO ä»»å‹™é¡å‹ã€‚
    :return: ç„¡è¿”å›å€¼ã€‚
    """
    # Resize the image to a standard size
    image = cv2.resize(image, (720, int(720 * (9 / 16))))
       
    # Predict the objects in the image using YOLO11 model
    res = model.predict(image, conf=conf)

    # Plot the detected objects on the video frame
    res_plotted = res[0].plot()
    st_frame.image(res_plotted,
                   caption='åµæ¸¬çµæœå½±ç‰‡',
                   channels="BGR",
                   use_container_width=True
                   )


@st.cache_resource
def load_model(model_path):
    """
    åœ¨æŒ‡å®š model_path ç›®éŒ„ä¸‹è¼‰ YOLO æ¨¡å‹ã€‚

    åƒæ•¸ï¼š

    model_path (str): YOLO æ¨¡å‹æª”æ¡ˆçš„è·¯å¾‘ã€‚

    è¿”å›ï¼š YOLO æ¨¡å‹ã€‚
    """
    model = YOLO(model_path)
    return model


def infer_uploaded_image(conf, model, task_type):
    """
    åŸ·è¡Œä¸Šå‚³åœ–ç‰‡çš„æ¨è«–
    :param conf (float): ç‰©é«”åµæ¸¬çš„ä¿¡å¿ƒæŒ‡æ•¸é–¾å€¼ã€‚
    :param model (YOLO11): YOLO11 æ¨¡å‹çš„å¯¦ä¾‹ã€‚
    :param task_type (string): YOLO ä»»å‹™é¡å‹ã€‚
    :return: ç„¡è¿”å›å€¼ã€‚
    """
    source_img = st.sidebar.file_uploader(
        label="é¸æ“‡åœ–ç‰‡æª”æ¡ˆ...",
        type=("jpg", "jpeg", "png", 'bmp', 'webp')
    )

    col1, col2 = st.columns(2)

    with col1:
        if source_img:
            uploaded_image = Image.open(source_img)
            # adding the uploaded image to the page with caption
            st.image(
                image=source_img,
                caption="ä¸Šå‚³åœ–ç‰‡",
                use_container_width=True
            )

    if source_img:
        if st.button("åŸ·è¡Œ"):
            with st.spinner("åŸ·è¡Œä¸­..."):
                if task_type == "ç‰©é«”åµæ¸¬": 
                    res = model.predict(uploaded_image,
                                        conf=conf)                    
                    res_plotted = res[0].plot()[:, :, ::-1]
                    with col2:
                        st.image(res_plotted,
                                 caption="åµæ¸¬çµæœåœ–ç‰‡",
                                 use_container_width=True)
                        try:
                            with st.expander("åµæ¸¬çµæœ"):
                                #boxes = res[0].boxes
                                #for box in boxes:
                                #    st.write(box.xywh)
                                for box in res[0].boxes:
                                    cords = box.xyxy[0].tolist()
                                    cords = [round(x) for x in cords]
                                    class_id = int(box.cls[0].item())
                                    conf = box.conf[0].item()
                                    conf = round(conf*100, 2)
                                    st.write("åˆ†é¡ç·¨è™Ÿ:", class_id)
                                    st.write("åˆ†é¡åç¨±:", model.names[class_id])
                                    st.write("æ–¹æ¡†åº§æ¨™:", cords)
                                    st.write("ä¿¡å¿ƒæŒ‡æ•¸:", conf, "%")
                                    st.write("------------------------")    
                        except Exception as ex:
                            st.write("å°šæœªæœ‰åœ–æª”ä¸Šå‚³!")
                            st.write(ex)
                elif task_type == "å§¿æ…‹è©•ä¼°":
                    res = model.predict(uploaded_image,
                                        conf=conf)
                    res_plotted = res[0].plot()[:, :, ::-1]
                    with col2:
                        st.image(res_plotted,
                                 caption="åµæ¸¬çµæœåœ–ç‰‡",
                                 use_container_width=True)
                        try:
                            with st.expander("åµæ¸¬çµæœ"):
                                for r in res:
                                    boxes = r.boxes
                                    kps = r.keypoints
                                    for idx, p in enumerate(kps):
                                        list_p = p.data.tolist()
                                        st.write("å§¿æ…‹è©•ä¼°åµæ¸¬çš„17å€‹é—œéµé»:", idx)
                                        for i, point in enumerate(list_p[0]):
                                            st.write(f"é—œéµé»: {i}: ({int(point[0])}, {int(point[1])})")
                                        st.write("------------------------")    
                                            
                        except Exception as ex:
                            st.write("å°šæœªä¸Šå‚³åœ–æª”!")
                            st.write(ex)                    

def infer_uploaded_video(conf, model, task_type):
    """
    åŸ·è¡Œä¸Šå‚³å½±ç‰‡çš„æ¨è«–
    :param conf (float): ç‰©é«”åµæ¸¬çš„ä¿¡å¿ƒæŒ‡æ•¸é–¾å€¼ã€‚
    :param model (YOLO11): YOLO11 æ¨¡å‹çš„å¯¦ä¾‹ã€‚
    :param task_type (string): YOLO ä»»å‹™é¡å‹ã€‚
    :return: ç„¡è¿”å›å€¼ã€‚
    """
    source_video = st.sidebar.file_uploader(
        label="é¸æ“‡ä¸Šå‚³å½±ç‰‡æª”..."
    )

    if source_video:
        st.video(source_video)

    if source_video:
        if st.button("åŸ·è¡Œ"):
            with st.spinner("åŸ·è¡Œä¸­..."):
                try:
                    tfile = tempfile.NamedTemporaryFile()
                    tfile.write(source_video.read())
                    vid_cap = cv2.VideoCapture(
                        tfile.name)
                    st_frame = st.empty()
                    while (vid_cap.isOpened()):
                        success, image = vid_cap.read()
                        if success:
                            _display_detected_frames(conf,
                                                     model,
                                                     st_frame,
                                                     image,
                                                     task_type
                                                     )
                        else:
                            vid_cap.release()
                            break
                except Exception as e:
                    st.error(f"è¼‰å…¥å½±ç‰‡éŒ¯èª¤: {e}")


def infer_uploaded_webcam(conf, model, task_type):
    """
    åŸ·è¡Œç¶²è·¯æ”å½±æ©ŸWebcamçš„æ¨è«–
    :param conf (float): ç‰©é«”åµæ¸¬çš„ä¿¡å¿ƒæŒ‡æ•¸é–¾å€¼ã€‚
    :param model (YOLO11): YOLO11 æ¨¡å‹çš„å¯¦ä¾‹ã€‚
    :param task_type (string): YOLO ä»»å‹™é¡å‹ã€‚
    :return: ç„¡è¿”å›å€¼ã€‚
    """
    try:
        flag = st.button(
            label="åœæ­¢åŸ·è¡Œ"
        )
        vid_cap = cv2.VideoCapture(0)  # local camera
        st_frame = st.empty()
        while not flag:
            success, image = vid_cap.read()
            if success:
                _display_detected_frames(
                    conf,
                    model,
                    st_frame,
                    image,
                    task_type
                )
            else:
                vid_cap.release()
                break
    except Exception as e:
        st.error(f"è¼‰å…¥ç¶²è·¯æ”å½±æ©ŸéŒ¯èª¤: {str(e)}")
        
def infer_uploaded_IPcam(conf, model, task_type):
    """
    åŸ·è¡Œç¶²è·¯ç›£æ§æ”å½±æ©ŸIP Cameraçš„æ¨è«–
    :param conf (float): ç‰©é«”åµæ¸¬çš„ä¿¡å¿ƒæŒ‡æ•¸é–¾å€¼ã€‚
    :param model (YOLO11): YOLO11 æ¨¡å‹çš„å¯¦ä¾‹ã€‚
    :param task_type (string): YOLO ä»»å‹™é¡å‹ã€‚
    :return: ç„¡è¿”å›å€¼ã€‚
    """
    # tw liveå¯æœå°‹å°ç£å³æ™‚å½±åƒï¼šhttps://trafficvideo2.tainan.gov.tw/b596d902
    # åœ¨å´é‚Šæ¬„ä¸­è¼¸å…¥ URL
    url = st.sidebar.text_input("è¼¸å…¥URL")
    if url:
        st.write(f"æ‚¨è¼¸å…¥çš„URLæ˜¯: {url}")
        try:
            flag = st.button(
                label="åœæ­¢åŸ·è¡Œ"
            )
            vid_cap = cv2.VideoCapture(url)  # IP camera
            st_frame = st.empty()
            while not flag:
                success, image = vid_cap.read()
                if success:
                    _display_detected_frames(
                        conf,
                        model,
                        st_frame,
                        image,
                        task_type
                    )
                else:
                    vid_cap.release()
                    break
        except Exception as e:
            st.error(f"è¼‰å…¥ç¶²è·¯æ”å½±æ©ŸéŒ¯èª¤: {str(e)}")        
    else:
        st.error(f"è«‹åœ¨å´é‚Šæ¬„[è¼¸å…¥URL]æ¬„ä½è¼¸å…¥ç¶²è·¯ç›£æ§æ”å½±æ©ŸIP Cameraçš„URLç¶²å€å¾Œ, æŒ‰Enteréµ")


# è¨­å®šé é¢ä½ˆå±€
st.set_page_config(
    page_title="Ultralytics YOLO11 æ¨¡å‹ä»»å‹™çš„äº’å‹•ä»‹é¢",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded"
    )

# ä¸»é é¢æ¨™é¡Œ
st.title("Ultralytics YOLO11 æ¨¡å‹ä»»å‹™çš„äº’å‹•ä»‹é¢")

# å´é‚Šæ¬„
st.sidebar.header("YOLOæ¨¡å‹è¨­ç½®")

# ä½œæ¥­é¸é …
task_type = st.sidebar.selectbox(
    "é¸æ“‡ä»»å‹™",
    ["ç‰©é«”åµæ¸¬",
     "å§¿æ…‹è©•ä¼°"]
)
# æ¨¡å‹é¸é …
model_type = None
if task_type == "ç‰©é«”åµæ¸¬":
    model_type = st.sidebar.selectbox(
        "é¸æ“‡æ¨¡å‹",
        DETECTION_MODEL_LIST
    )
elif task_type == "å§¿æ…‹è©•ä¼°":
    model_type = st.sidebar.selectbox(
        "é¸æ“‡æ¨¡å‹",
        POSE_MODEL_LIST
    )
else:
    st.error("ç›®å‰å·²ç¶“å¯¦ä½œ 'ç‰©é«”åµæ¸¬' å’Œ 'å§¿æ…‹è©•ä¼°' åŠŸèƒ½")
# ä¿¡å¿ƒæŒ‡æ•¸é¸é …
confidence = float(st.sidebar.slider(
    "é¸æ“‡ä¿¡å¿ƒæŒ‡æ•¸", 30, 100, 50)) / 100
# å–å¾—æ¨¡å‹å„²å­˜çš„è·¯å¾‘
model_path = ""
if model_type:
    if task_type == "ç‰©é«”åµæ¸¬":
        model_path = Path(DETECTION_MODEL_DIR, str(model_type))
    elif task_type == "å§¿æ…‹è©•ä¼°":
        model_path = Path(POSE_MODEL_DIR, str(model_type))
else:
    st.error("è«‹åœ¨å´é‚Šæ¬„é¸æ“‡æ¨¡å‹ç¨®é¡")

# è¼‰å…¥YOLOé è¨“ç·´æ¨¡å‹
try:
    model = load_model(model_path)
except Exception as e:
    st.error(f"ç„¡æ³•è¼‰å…¥æ¨¡å‹. è«‹ç¢ºèªæ¨¡å‹è·¯å¾‘: {model_path}")

# åœ–ç‰‡/å½±ç‰‡é¸é …
st.sidebar.header("åœ–ç‰‡/å½±ç‰‡è¨­ç½®")
source_selectbox = st.sidebar.selectbox(
    "é¸æ“‡ä¾†æº",
    SOURCES_LIST
)

source_img = None
if source_selectbox == SOURCES_LIST[0]:   # Image
    infer_uploaded_image(confidence, model, task_type)
elif source_selectbox == SOURCES_LIST[1]: # Video
    infer_uploaded_video(confidence, model, task_type)
elif source_selectbox == SOURCES_LIST[2]: # Webcam
    infer_uploaded_webcam(confidence, model, task_type)
elif source_selectbox == SOURCES_LIST[3]: # IPcam
    infer_uploaded_IPcam(confidence, model, task_type)    
else:
    st.error("ç›®å‰è³‡æ–™ä¾†æºæ”¯æ´'åœ–ç‰‡' ,'å½±ç‰‡' ,'ç¶²è·¯æ”å½±æ©Ÿ' å’Œ 'ç¶²è·¯ç›£æ§æ”å½±æ©Ÿ'")